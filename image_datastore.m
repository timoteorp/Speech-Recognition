%handle with da image data generated by computeScaleogram
 imagePath = 'C:\Users\timot\OneDrive\Área de Trabalho\Projetos Faculdade\TCC\Speech Commands\Imagens 40 90 10_voices';
 allImages = imageDatastore(imagePath,'IncludeSubfolders',true,'LabelSource','foldernames');

%
%mask = ~ismember(allImages.Labels,"unknown")
%allImages = getSubsetDatastore(allImages,mask)
%% 
rng default
[imgsTrain,imgsValidation] = splitEachLabel(allImages,0.8,'randomized');
disp(['Number of training images: ',num2str(numel(imgsTrain.Files))]);

%% 
disp(['Number of validation images: ',num2str(numel(imgsValidation.Files))]);

YTrain = imgsTrain.Labels;
YValidation = imgsValidation.Labels;
%% 
teste = readall(imgsTrain);
imageSize = size(read(imgsTrain));
XTrain = table_to_array(teste);
sz = size(imgsTrain);
specSize = sz(1:2);
augmenter = imageDataAugmenter( ...
    'RandXTranslation',[-10 10], ...
    'RandXScale',[0.8 1.2], ...
    'FillValue',log10(1e-6));
augimdsTrain = augmentedImageDatastore(imageSize,XTrain,YTrain, ...
    'DataAugmentation',augmenter);


%% Rede Neural
%% Rede Projetada
classNames = categories(YTrain);
classWeights = 1./countcats(YTrain);
classWeights = classWeights/mean(classWeights);
numClasses = numel(classNames);
imageSize = size(read(imgsTrain));

dropoutProb = 0.2;
layers = [
    imageInputLayer(imageSize)

    convolution2dLayer(3,16,'Padding','same')
    batchNormalizationLayer
    reluLayer

    maxPooling2dLayer(2,'Stride',2)

    convolution2dLayer(3,32,'Padding','same')
    batchNormalizationLayer
    reluLayer

    maxPooling2dLayer(2,'Stride',2,'Padding',[0,1])

    dropoutLayer(dropoutProb)
    convolution2dLayer(3,64,'Padding','same')
    batchNormalizationLayer
    reluLayer

    dropoutLayer(dropoutProb)
    convolution2dLayer(3,64,'Padding','same')
    batchNormalizationLayer
    reluLayer

    maxPooling2dLayer(2,'Stride',2,'Padding',[0,1])

    dropoutLayer(dropoutProb)
    convolution2dLayer(3,64,'Padding','same')
    batchNormalizationLayer
    reluLayer

    dropoutLayer(dropoutProb)
    convolution2dLayer(3,64,'Padding','same')
    batchNormalizationLayer
    reluLayer

    maxPooling2dLayer([1 13])

    fullyConnectedLayer(numClasses)
    softmaxLayer
    weightedCrossEntropyLayer(classNames,classWeights)];
% 
% %% GoogleNet
% % net = googlenet;
% % lgraph = layerGraph(net);
% % numberOfLayers = numel(lgraph.Layers);
% % newDropoutLayer = dropoutLayer(0.6,'Name','new_Dropout');
% % lgraph = addLayers(lgraph,newDropoutLayer)
% % %lgraph = replaceLayer(lgraph,'pool5-drop_7x7_s1',newDropoutLayer);
% % lgraph = connectLayers(lgraph,'pool5-7x7_s1','new_Dropout');
% % lgraph = removeLayers(lgraph,'pool5-drop_7x7_s1');
% % numClasses = numel(categories(imgsTrain.Labels));
% % newConnectedLayer = fullyConnectedLayer(numClasses,'Name','new_fc',...
% %     'WeightLearnRateFactor',5,'BiasLearnRateFactor',5);
% % lgraph = removeLayers(lgraph,'loss3-classifier');
% % lgraph = addLayers(lgraph,newConnectedLayer);
% % lgraph = connectLayers(lgraph,'new_Dropout','new_fc');
% % lgraph = connectLayers(lgraph,'new_fc','prob');
% % %lgraph = replaceLayer(lgraph,'loss3-classifier',newConnectedLayer);
% % newClassLayer = classificationLayer('Name','new_classoutput');
% % lgraph = removeLayers(lgraph,'output');
% % lgraph = addLayers(lgraph,newClassLayer);
% % lgraph = connectLayers(lgraph,'prob','new_classoutput');
% % %lgraph = replaceLayer(lgraph,'output',newClassLayer);
% % options = trainingOptions('sgdm',...
% %     'MiniBatchSize',64,...
% %     'MaxEpochs',20,...
% %     'InitialLearnRate',1e-4,...
% %     'ValidationData',imgsValidation,...
% %     'ValidationFrequency',10,...
% %     'Verbose',1,...
% %     'ExecutionEnvironment','cpu',...
% %     'Plots','training-progress');
% % rng default
% % trainedGN = trainNetwork(imgsTrain,lgraph,options);
% 
% 
% %% 
% %  histogram(teste{:},'EdgeColor','none','Normalization','pdf')
% %  axis tight
% %  ax = gca;
% %  ax.YScale = 'log';
% %  xlabel("Input Pixel Value")
% %  ylabel("Probability Density")
% % 
% 
% 
%% Treinamento
miniBatchSize = 128;
validationFrequency = floor(numel(YTrain)/miniBatchSize);
options = trainingOptions('adam', ...
    'InitialLearnRate',5e-4, ...
    'MaxEpochs',25, ...
    'MiniBatchSize',miniBatchSize, ...
    'Shuffle','every-epoch', ...
    'Plots','training-progress', ...
    'Verbose',false, ...
    'ValidationData',{imgsValidation,YValidation}, ...
    'ValidationFrequency',validationFrequency, ...
    'ValidationPatience',Inf, ...
    'LearnRateSchedule','piecewise', ...
    'LearnRateDropFactor',0.1, ...
    'LearnRateDropPeriod',20);

doTraining = true;
if doTraining
    trainedNet = trainNetwork(imgsTrain,layers,options);
else
    s = load('commandNet.mat');
    trainedNet = s.trainedNet;
end

save('commandNet_retrained.mat','trainedNet');



